{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2e8c44162bf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!/usr/bin/env python3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0muppercase_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUppercaseData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from uppercase_data import UppercaseData\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "import neptune\n",
    "neptune.init(project_qualified_name='amdalifuk/c10', api_token='=') # add your \n",
    "\n",
    "# Report only TF errors by default\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")\n",
    "\n",
    "# 2f67b427-a885-11e7-a937-00505601122b\n",
    "# c751264b-78ee-11eb-a1a9-005056ad4f31\n",
    "\n",
    "\n",
    "# Fix random seeds and threads\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(4)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(4)\n",
    "\n",
    "# Load data\n",
    "\n",
    "\n",
    "# TODO: Implement a suitable model, optionally including regularization, select\n",
    "# good hyperparameters and train the model.\n",
    "#\n",
    "# The inputs are _windows_ of fixed size (`args.window` characters on left,\n",
    "# the character in question, and `args.window` characters on right), where\n",
    "# each character is represented by a `tf.int32` index. To suitably represent\n",
    "# the characters, you can:\n",
    "# - Convert the character indices into _one-hot encoding_. There is no\n",
    "#   explicit Keras layer, but you can\n",
    "#   - use a Lambda layer which can encompass any function:\n",
    "#       tf.keras.Sequential([\n",
    "#         tf.keras.layers.InputLayer(input_shape=[2 * args.window + 1], dtype=tf.int32),\n",
    "#         tf.keras.layers.Lambda(lambda x: tf.one_hot(x, len(uppercase_data.train.alphabet))),\n",
    "#   - or use Functional API and then any TF function can be used\n",
    "#     as a Keras layer:\n",
    "#       inputs = tf.keras.layers.Input(shape=[2 * args.window + 1], dtype=tf.int32)\n",
    "#       encoded = tf.one_hot(inputs, len(uppercase_data.train.alphabet))\n",
    "#   You can then flatten the one-hot encoded windows and follow with a dense layer.\n",
    "# - Alternatively, you can use `tf.keras.layers.Embedding` (which is an efficient\n",
    "#   implementation of one-hot encoding followed by a Dense layer) and flatten afterwards.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 11, 30)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 330)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               33100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 43,402\n",
      "Trainable params: 43,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#hloubka a počet parametrů, dropout\n",
    "hidden_layers = [400]\n",
    "dropout = 0.03 #True/False\n",
    "l2 = 0.0001 #0,0.1\n",
    "bn = True #True/False\n",
    "lr = 0.0001\n",
    "window = 5\n",
    "alphabet_size = 60\n",
    "label_smoothing = 0\n",
    "loss = tf.losses.CategoricalCrossentropy( label_smoothing=label_smoothing) #?\n",
    "batch_size = 1000\n",
    "afunkce= 'relu'\n",
    "epochs = 20\n",
    "\n",
    "uppercase_data = UppercaseData(window, alphabet_size)\n",
    "labels = tf.keras.utils.to_categorical(uppercase_data.train.data[\"labels\"])\n",
    "labels_dev = tf.keras.utils.to_categorical(uppercase_data.dev.data[\"labels\"])\n",
    "\n",
    "def get_network():\n",
    "    \n",
    "    l1l2_regularizer = None\n",
    "    \n",
    "    if l2 != 0:\n",
    "        l1l2_regularizer = tf.keras.regularizers.L1L2(l1=0, l2=l2)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(\n",
    "            input_shape=[2 * window + 1], dtype=tf.int32),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.one_hot(x, len(uppercase_data.train.alphabet)))])\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    for hidden_layer in hidden_layers:\n",
    "        model.add(tf.keras.layers.Dense(hidden_layer,\n",
    "                  activation=afunkce, kernel_regularizer=l1l2_regularizer))\n",
    "        \n",
    "        if dropout != 0:\n",
    "            model.add(tf.keras.layers.Dropout(dropout))\n",
    "        \n",
    "        if bn:\n",
    "            model.add(tf.keras.layers.BatchNormalization() )\n",
    "            \n",
    "            \n",
    "\n",
    "    model.add(tf.keras.layers.Dense(2,\n",
    "              activation=tf.nn.softmax, kernel_regularizer=l1l2_regularizer))\n",
    "    return model\n",
    "    \n",
    "model = get_network()\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam( lr ),\n",
    "        loss=loss,\n",
    "        metrics=[tf.metrics.CategoricalAccuracy(name=\"accuracy\")],\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info (NVML): Uninitialized. GPU usage metrics may not be reported. For more information, see https://docs.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/amdalifuk/c10/e/C10-7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PARAMS = {\n",
    "    'hidden_layers': hidden_layers,\n",
    "    'dropout': dropout,\n",
    "    'afunkce': afunkce,\n",
    "    'l2': l2,\n",
    "    'bn': bn,\n",
    "    'lr': lr,\n",
    "    'window': window,\n",
    "    'loss': loss,\n",
    "    'batch_size': batch_size,\n",
    "    'label_smoothing': label_smoothing,\n",
    "    'alphabet_size': alphabet_size,\n",
    "    'epochs': epochs,                 \n",
    "         }\n",
    "neptune.create_experiment(params=PARAMS)\n",
    "neptune.send_artifact('uppercase.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0585 - accuracy: 0.9782 - val_loss: 0.0588 - val_accuracy: 0.9777\n",
      "Epoch 2/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0582 - accuracy: 0.9783 - val_loss: 0.0586 - val_accuracy: 0.9777\n",
      "Epoch 3/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0579 - accuracy: 0.9785 - val_loss: 0.0583 - val_accuracy: 0.9778\n",
      "Epoch 4/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0576 - accuracy: 0.9786 - val_loss: 0.0580 - val_accuracy: 0.9780\n",
      "Epoch 5/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0573 - accuracy: 0.9787 - val_loss: 0.0577 - val_accuracy: 0.9781\n",
      "Epoch 6/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0571 - accuracy: 0.9788 - val_loss: 0.0575 - val_accuracy: 0.9782\n",
      "Epoch 7/20\n",
      "1223/1223 [==============================] - 6s 5ms/step - loss: 0.0568 - accuracy: 0.9790 - val_loss: 0.0573 - val_accuracy: 0.9782\n",
      "Epoch 8/20\n",
      "1223/1223 [==============================] - 6s 5ms/step - loss: 0.0565 - accuracy: 0.9791 - val_loss: 0.0570 - val_accuracy: 0.9784\n",
      "Epoch 9/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0563 - accuracy: 0.9792 - val_loss: 0.0568 - val_accuracy: 0.9785\n",
      "Epoch 10/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0560 - accuracy: 0.9793 - val_loss: 0.0566 - val_accuracy: 0.9786\n",
      "Epoch 11/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0558 - accuracy: 0.9794 - val_loss: 0.0564 - val_accuracy: 0.9787\n",
      "Epoch 12/20\n",
      "1223/1223 [==============================] - 6s 5ms/step - loss: 0.0555 - accuracy: 0.9795 - val_loss: 0.0562 - val_accuracy: 0.9788\n",
      "Epoch 13/20\n",
      "1223/1223 [==============================] - 5s 4ms/step - loss: 0.0553 - accuracy: 0.9796 - val_loss: 0.0560 - val_accuracy: 0.9789\n",
      "Epoch 14/20\n",
      " 315/1223 [======>.......................] - ETA: 4s - loss: 0.0552 - accuracy: 0.9797"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d76883f283c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mneptune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1-val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m model.fit(uppercase_data.train.data[\"windows\"], labels, batch_size=batch_size, shuffle=True,\n\u001b[0m\u001b[0;32m     14\u001b[0m           validation_data=(uppercase_data.dev.data[\"windows\"], labels_dev), epochs=epochs, callbacks=[CustomCallback()])\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#13 epoch\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "class CustomCallback(Callback):        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        neptune.log_metric('loss', logs['loss'])\n",
    "        neptune.log_metric('1-accuracy', 1-logs['accuracy'])\n",
    "        \n",
    "        if 'val_loss' in logs:\n",
    "            neptune.log_metric('val_loss', logs['val_loss'])\n",
    "            neptune.log_metric('1-val_accuracy', 1-logs['val_accuracy'])\n",
    "            \n",
    "model.fit(uppercase_data.train.data[\"windows\"], labels, batch_size=batch_size, shuffle=True,\n",
    "          validation_data=(uppercase_data.dev.data[\"windows\"], labels_dev), epochs=epochs, callbacks=[CustomCallback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Generate correctly capitalized test set.\n",
    "# Use `uppercase_data.test.text` as input, capitalize suitable characters,\n",
    "# and write the result to predictions_file (which is\n",
    "# `uppercase_test.txt` in the `args.logdir` directory).\n",
    "\n",
    "predictions = model.predict(uppercase_data.test.data[\"windows\"])\n",
    "text_result = list(uppercase_data.test.text)\n",
    "\n",
    "with open(\"input.txt\", \"w\", encoding=\"utf-8\") as predictions_file:\n",
    "    predictions_file.write(uppercase_data.test.text)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i][1] >= 0.5:\n",
    "        if text_result[i] == text_result[i].upper().lower():\n",
    "            text_result[i] = text_result[i].upper()\n",
    "\n",
    "text_result = \"\".join(text_result)\n",
    "with open(\"uppercase_test.txt\", \"w\", encoding=\"utf-8\") as predictions_file:\n",
    "    predictions_file.write(text_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}